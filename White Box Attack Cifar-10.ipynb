{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - White Attack with Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR_model, self).__init__()\n",
    "        self.convblock = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            # Block 2\n",
    "            nn.Conv2d(64,128,3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,128,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        )\n",
    "        self.fcblock = nn.Sequential(\n",
    "            # FC Block\n",
    "            nn.Linear(128*5*5, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convblock(x)\n",
    "        x = x.view(-1, 128*5*5)\n",
    "        x = self.fcblock(x)\n",
    "        return x\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"CIFAR_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CIFAR_model(\n",
       "  (convblock): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fcblock): Sequential(\n",
       "    (0): Linear(in_features=3200, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (6): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CIFAR_model().cuda()\n",
    "model.load_state_dict(torch.load(\"./models/CIFAR_model.state\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "gt = []\n",
    "\n",
    "for filename in glob.glob('./confident_input/CIFAR_model/' + '*.data'):\n",
    "    img = torch.load(filename)\n",
    "    modelout = model(img[None,...])\n",
    "    INITCONF, TRUECLASS = torch.max(modelout, 1)\n",
    "    #print(TRUECLASS)\n",
    "    #print(CIFAR_CLASSES[TRUECLASS])\n",
    "    d.append(img)\n",
    "    gt.append(TRUECLASS)\n",
    "    \n",
    "print(len(d))\n",
    "print(len(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize = (5, 15))\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    #plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_CLASSES = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "0.2686840174374757\n",
      "tensor([25.5609], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# First white box attack BIM\n",
    "# change iters increase attack success rate but increase L2 loss\n",
    "# iter = 0 80\n",
    "\n",
    "BIM_time = []\n",
    "BIM_L2 = []\n",
    "BIM_output = []\n",
    "BIM_correct = 0\n",
    "#BIM = torchattacks.BIM(model, eps=4/255, alpha=1/255, iters=0)\n",
    "BIM = torchattacks.BIM(model, eps=4/255, alpha=1/255, iters=40)\n",
    "for i in range(len(d)):\n",
    "    t0 = time.time()\n",
    "    images = BIM(d[i][None,...], gt[i])\n",
    "    #print(gt[i])\n",
    "    dt = time.time() - t0\n",
    "    BIM_time.append(dt)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    L2 = torch.norm(images.view(1,-1) - d[i].view(1,-1), dim=1)\n",
    "    #print(L2)\n",
    "    BIM_L2.append(L2)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    BIM_output.append(pre)\n",
    "    #print(pre)\n",
    "    if gt[i] != pre:\n",
    "        BIM_correct+=1\n",
    "        \n",
    "print(BIM_correct)\n",
    "average_time = np.sum(np.array(BIM_time))/len(d)\n",
    "average_L2 = np.sum(np.array(BIM_L2))/len(d)\n",
    "print(average_time)\n",
    "print(average_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "0.07082464628749424\n",
      "tensor([14.1452], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# then try white box attack StepLL = torchattacks.StepLL(model, eps=4/255, alpha=1/255, iters=0)\n",
    "StepLL_time = []\n",
    "StepLL_L2 = []\n",
    "StepLL_output = []\n",
    "StepLL_correct = 0\n",
    "#BIM = torchattacks.BIM(model, eps=4/255, alpha=1/255, iters=0)\n",
    "StepLL = torchattacks.StepLL(model, eps=4/255, alpha=1/255, iters=10)\n",
    "for i in range(len(d)):\n",
    "    t0 = time.time()\n",
    "    images = StepLL(d[i][None,...], gt[i])\n",
    "    #print(gt[i])\n",
    "    dt = time.time() - t0\n",
    "    StepLL_time.append(dt)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    L2 = torch.norm(images.view(1,-1) - d[i].view(1,-1), dim=1)\n",
    "    #print(L2)\n",
    "    StepLL_L2.append(L2)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    StepLL_output.append(pre)\n",
    "    #print(pre)\n",
    "    if gt[i] != pre:\n",
    "        StepLL_correct+=1\n",
    "        \n",
    "print(StepLL_correct)\n",
    "average_time = np.sum(np.array(StepLL_time))/len(d)\n",
    "average_L2 = np.sum(np.array(StepLL_L2))/len(d)\n",
    "print(average_time)\n",
    "print(average_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "0.02826858891381158\n",
      "tensor([38.3447], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# then try white box attack RFGSM\n",
    "StepLL_time = []\n",
    "StepLL_L2 = []\n",
    "StepLL_output = []\n",
    "StepLL_correct = 0\n",
    "#BIM = torchattacks.BIM(model, eps=4/255, alpha=1/255, iters=0)\n",
    "RFGSM = torchattacks.RFGSM(model, eps=16/255, alpha=8/255, iters=5)\n",
    "for i in range(len(d)):\n",
    "    t0 = time.time()\n",
    "    images = RFGSM(d[i][None,...], gt[i])\n",
    "    #print(gt[i])\n",
    "    dt = time.time() - t0\n",
    "    StepLL_time.append(dt)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    L2 = torch.norm(images.view(1,-1) - d[i].view(1,-1), dim=1)\n",
    "    #print(L2)\n",
    "    StepLL_L2.append(L2)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    StepLL_output.append(pre)\n",
    "    #print(pre)\n",
    "    if gt[i] != pre:\n",
    "        StepLL_correct+=1\n",
    "        \n",
    "print(StepLL_correct)\n",
    "average_time = np.sum(np.array(StepLL_time))/len(d)\n",
    "average_L2 = np.sum(np.array(StepLL_L2))/len(d)\n",
    "print(average_time)\n",
    "print(average_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "0.24012919708534522\n",
      "tensor([37.1240], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# PGD = torchattacks.PGD(model, eps=0.3, alpha=2/255, iters=40)\n",
    "# then try white box attack RFGSM\n",
    "StepLL_time = []\n",
    "StepLL_L2 = []\n",
    "StepLL_output = []\n",
    "StepLL_correct = 0\n",
    "#BIM = torchattacks.BIM(model, eps=4/255, alpha=1/255, iters=0)\n",
    "PGD = torchattacks.PGD(model, eps=0.3, alpha=2/255, iters=40)\n",
    "for i in range(len(d)):\n",
    "    t0 = time.time()\n",
    "    images = PGD(d[i][None,...], gt[i])\n",
    "    #print(gt[i])\n",
    "    dt = time.time() - t0\n",
    "    StepLL_time.append(dt)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    L2 = torch.norm(images.view(1,-1) - d[i].view(1,-1), dim=1)\n",
    "    #print(L2)\n",
    "    StepLL_L2.append(L2)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    StepLL_output.append(pre)\n",
    "    #print(pre)\n",
    "    if gt[i] != pre:\n",
    "        StepLL_correct+=1\n",
    "        \n",
    "print(StepLL_correct)\n",
    "average_time = np.sum(np.array(StepLL_time))/len(d)\n",
    "average_L2 = np.sum(np.array(StepLL_L2))/len(d)\n",
    "print(average_time)\n",
    "print(average_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "0.24318546056747437\n",
      "tensor([37.3128], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# RPGD = torchattacks.PGD(model, eps=0.3, alpha=2/255, iters=40, random_start=True)\n",
    "StepLL_time = []\n",
    "StepLL_L2 = []\n",
    "StepLL_output = []\n",
    "StepLL_correct = 0\n",
    "#BIM = torchattacks.BIM(model, eps=4/255, alpha=1/255, iters=0)\n",
    "RPGD = torchattacks.PGD(model, eps=0.3, alpha=2/255, iters=40, random_start=True)\n",
    "for i in range(len(d)):\n",
    "    t0 = time.time()\n",
    "    images = RPGD(d[i][None,...], gt[i])\n",
    "    #print(gt[i])\n",
    "    dt = time.time() - t0\n",
    "    StepLL_time.append(dt)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    L2 = torch.norm(images.view(1,-1) - d[i].view(1,-1), dim=1)\n",
    "    #print(L2)\n",
    "    StepLL_L2.append(L2)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    StepLL_output.append(pre)\n",
    "    #print(pre)\n",
    "    if gt[i] != pre:\n",
    "        StepLL_correct+=1\n",
    "        \n",
    "print(StepLL_correct)\n",
    "average_time = np.sum(np.array(StepLL_time))/len(d)\n",
    "average_L2 = np.sum(np.array(StepLL_L2))/len(d)\n",
    "print(average_time)\n",
    "print(average_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "0.1070918771955702\n",
      "tensor([0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# DeepFool = torchattacks.DeepFool(model, iters=10)\n",
    "StepLL_time = []\n",
    "StepLL_L2 = []\n",
    "StepLL_output = []\n",
    "StepLL_correct = 0\n",
    "#BIM = torchattacks.BIM(model, eps=4/255, alpha=1/255, iters=0)\n",
    "DeepFool = torchattacks.DeepFool(model, iters=10)\n",
    "for i in range(len(d)):\n",
    "    t0 = time.time()\n",
    "    images = DeepFool(d[i][None,...], gt[i])\n",
    "    #print(gt[i])\n",
    "    dt = time.time() - t0\n",
    "    StepLL_time.append(dt)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    L2 = torch.norm(images.view(1,-1) - d[i].view(1,-1), dim=1)\n",
    "    #print(L2)\n",
    "    StepLL_L2.append(L2)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "    StepLL_output.append(pre)\n",
    "    #print(pre)\n",
    "    if gt[i] != pre:\n",
    "        StepLL_correct+=1\n",
    "        \n",
    "print(StepLL_correct)\n",
    "average_time = np.sum(np.array(StepLL_time))/len(d)\n",
    "average_L2 = np.sum(np.array(StepLL_L2))/len(d)\n",
    "print(average_time)\n",
    "print(average_L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4], device='cuda:0')\n",
      "deer\n"
     ]
    }
   ],
   "source": [
    "# test a deer\n",
    "modelout = model(data[None,...])\n",
    "INITCONF, TRUECLASS = torch.max(modelout, 1)\n",
    "print(TRUECLASS)\n",
    "print(CIFAR_CLASSES[TRUECLASS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04505348205566406\n",
      "tensor([2], device='cuda:0')\n",
      "bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "images = BIM(data[None,...], TRUECLASS[...])\n",
    "dt = time.time() - t0\n",
    "print(dt)\n",
    "#labels = labels.to(device)\n",
    "outputs = model(images)\n",
    "\n",
    "_, pre = torch.max(outputs.data, 1)\n",
    "print(pre)\n",
    "print(CIFAR_CLASSES[pre])\n",
    "imshow(images.squeeze().cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GCN]",
   "language": "python",
   "name": "conda-env-GCN-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
